Results for Full Dataset - Multiclass Prediction
======================================================================

=== RANKING TABLE ===
Model                   Accuracy   Bal.Acc      MCC    Kappa   MacroAUC
------------------------------------------------------------------------
CatBoost                  0.5315    0.4592   0.2517   0.2252     0.6676
AdaBoost                  0.5315    0.4602   0.2532   0.2273     0.6533
Gradient Boosting         0.5250    0.4641   0.2404   0.2277     0.6588
Logistic Regression       0.5233    0.4610   0.2376   0.2235     0.6666
Extra Trees               0.5191    0.4544   0.2292   0.2131     0.6451
XGBoost                   0.5151    0.4573   0.2255   0.2149     0.6532
Random Forest             0.5136    0.4477   0.2182   0.2036     0.6458
LightGBM                  0.5136    0.4559   0.2220   0.2124     0.6546
SVM                       0.4735    0.4656   0.2119   0.2091     0.6508
KNN                       0.4421    0.4083   0.1273   0.1270     0.5847

=== PER-CLASS AUC (OvR) ===
Model                      AwayWin        Draw     HomeWin
----------------------------------------------------------
CatBoost                    0.7192      0.5683      0.7148
AdaBoost                    0.7109      0.5427      0.7061
Gradient Boosting           0.7016      0.5665      0.7078
Logistic Regression         0.7161      0.5707      0.7127
Extra Trees                 0.6945      0.5410      0.6996
XGBoost                     0.6995      0.5599      0.6998
Random Forest               0.6944      0.5436      0.6993
LightGBM                    0.7010      0.5624      0.7000
SVM                         0.6971      0.5570      0.6979
KNN                         0.6140      0.5174      0.6222

=== DETAILED RESULTS ===

Model: CatBoost
------------------------------
Accuracy:          0.5315
Balanced Accuracy: 0.4592
MCC:               0.2517
Cohen's Kappa:     0.2252
Macro ROC-AUC:     0.6676

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.50      0.55      0.52      1593
        Draw       0.38      0.01      0.02      1338
     HomeWin       0.55      0.82      0.66      2330

    accuracy                           0.53      5261
   macro avg       0.48      0.46      0.40      5261
weighted avg       0.49      0.53      0.45      5261

Confusion Matrix:
[[ 871   11  711]
 [ 457   15  866]
 [ 406   14 1910]]
Training curve: metric=MultiClass, best_iter=1, final_train=0.9258, final_val=0.9836

======================================================================
Model: AdaBoost
------------------------------
Accuracy:          0.5315
Balanced Accuracy: 0.4602
MCC:               0.2532
Cohen's Kappa:     0.2273
Macro ROC-AUC:     0.6533

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.50      0.57      0.53      1593
        Draw       0.16      0.00      0.00      1338
     HomeWin       0.55      0.81      0.66      2330

    accuracy                           0.53      5261
   macro avg       0.40      0.46      0.40      5261
weighted avg       0.43      0.53      0.45      5261

Confusion Matrix:
[[ 904   10  679]
 [ 486    3  849]
 [ 435    6 1889]]
======================================================================
Model: Gradient Boosting
------------------------------
Accuracy:          0.5250
Balanced Accuracy: 0.4641
MCC:               0.2404
Cohen's Kappa:     0.2277
Macro ROC-AUC:     0.6588

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.51      0.50      0.50      1593
        Draw       0.34      0.11      0.17      1338
     HomeWin       0.56      0.78      0.65      2330

    accuracy                           0.52      5261
   macro avg       0.47      0.46      0.44      5261
weighted avg       0.49      0.52      0.48      5261

Confusion Matrix:
[[ 798  142  653]
 [ 411  152  775]
 [ 369  149 1812]]
Training curve: metric=accuracy, best_iter=55, final_train=0.5704, final_val=0.5250

======================================================================
Model: Logistic Regression
------------------------------
Accuracy:          0.5233
Balanced Accuracy: 0.4610
MCC:               0.2376
Cohen's Kappa:     0.2235
Macro ROC-AUC:     0.6666

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.50      0.52      0.51      1593
        Draw       0.33      0.09      0.14      1338
     HomeWin       0.56      0.78      0.65      2330

    accuracy                           0.52      5261
   macro avg       0.46      0.46      0.43      5261
weighted avg       0.48      0.52      0.48      5261

Confusion Matrix:
[[ 826  116  651]
 [ 429  118  791]
 [ 395  126 1809]]
======================================================================
Model: Extra Trees
------------------------------
Accuracy:          0.5191
Balanced Accuracy: 0.4544
MCC:               0.2292
Cohen's Kappa:     0.2131
Macro ROC-AUC:     0.6451

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.49      0.51      0.50      1593
        Draw       0.33      0.07      0.12      1338
     HomeWin       0.55      0.78      0.65      2330

    accuracy                           0.52      5261
   macro avg       0.46      0.45      0.42      5261
weighted avg       0.48      0.52      0.47      5261

Confusion Matrix:
[[ 808  102  683]
 [ 419   96  823]
 [ 413   90 1827]]
======================================================================
Model: XGBoost
------------------------------
Accuracy:          0.5151
Balanced Accuracy: 0.4573
MCC:               0.2255
Cohen's Kappa:     0.2149
Macro ROC-AUC:     0.6532

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.49      0.52      0.51      1593
        Draw       0.31      0.10      0.16      1338
     HomeWin       0.55      0.75      0.64      2330

    accuracy                           0.52      5261
   macro avg       0.45      0.46      0.43      5261
weighted avg       0.48      0.52      0.48      5261

Confusion Matrix:
[[ 827  126  640]
 [ 438  140  760]
 [ 406  181 1743]]
Training curve: metric=mlogloss, best_iter=28, final_train=0.7460, final_val=1.0018

======================================================================
Model: Random Forest
------------------------------
Accuracy:          0.5136
Balanced Accuracy: 0.4477
MCC:               0.2182
Cohen's Kappa:     0.2036
Macro ROC-AUC:     0.6458

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.51      0.47      0.49      1593
        Draw       0.27      0.08      0.12      1338
     HomeWin       0.54      0.79      0.64      2330

    accuracy                           0.51      5261
   macro avg       0.44      0.45      0.42      5261
weighted avg       0.46      0.51      0.47      5261

Confusion Matrix:
[[ 753  150  690]
 [ 379  107  852]
 [ 345  143 1842]]
======================================================================
Model: LightGBM
------------------------------
Accuracy:          0.5136
Balanced Accuracy: 0.4559
MCC:               0.2220
Cohen's Kappa:     0.2124
Macro ROC-AUC:     0.6546

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.50      0.48      0.49      1593
        Draw       0.32      0.13      0.19      1338
     HomeWin       0.55      0.76      0.64      2330

    accuracy                           0.51      5261
   macro avg       0.46      0.46      0.44      5261
weighted avg       0.48      0.51      0.48      5261

Confusion Matrix:
[[ 765  181  647]
 [ 387  176  775]
 [ 373  196 1761]]
Training curve: metric=multi_logloss, best_iter=27, final_train=0.7161, final_val=1.0019

======================================================================
Model: SVM
------------------------------
Accuracy:          0.4735
Balanced Accuracy: 0.4656
MCC:               0.2119
Cohen's Kappa:     0.2091
Macro ROC-AUC:     0.6508

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.48      0.53      0.50      1593
        Draw       0.29      0.38      0.33      1338
     HomeWin       0.64      0.49      0.56      2330

    accuracy                           0.47      5261
   macro avg       0.47      0.47      0.46      5261
weighted avg       0.50      0.47      0.48      5261

Confusion Matrix:
[[ 839  493  261]
 [ 457  506  375]
 [ 447  737 1146]]
======================================================================
Model: KNN
------------------------------
Accuracy:          0.4421
Balanced Accuracy: 0.4083
MCC:               0.1273
Cohen's Kappa:     0.1270
Macro ROC-AUC:     0.5847

Classification Report:
              precision    recall  f1-score   support

     AwayWin       0.43      0.41      0.42      1593
        Draw       0.26      0.23      0.25      1338
     HomeWin       0.53      0.59      0.56      2330

    accuracy                           0.44      5261
   macro avg       0.41      0.41      0.41      5261
weighted avg       0.43      0.44      0.44      5261

Confusion Matrix:
[[ 652  359  582]
 [ 400  305  633]
 [ 474  487 1369]]
======================================================================
