Results for Full Dataset - Multiclass Prediction
======================================================================

=== RANKING TABLE ===
Model                   Accuracy   Bal.Acc      MCC    Kappa   MacroAUC
------------------------------------------------------------------------
Random Forest             0.5197    0.4432   0.2257   0.1988     0.6374
Neural Network            0.5183    0.4528   0.2286   0.2123     0.6545
Extra Trees               0.5134    0.4416   0.2159   0.1948     0.6442
SVM                       0.4839    0.4609   0.2102   0.2092     0.6483
CatBoost                  0.4733    0.4630   0.2138   0.2071     0.6629
Logistic Regression       0.4678    0.4684   0.2143   0.2090     0.6598
AdaBoost                  0.4640    0.4656   0.2129   0.2053     0.6547
XGBoost                   0.4554    0.4487   0.1881   0.1837     0.6348
KNN                       0.4541    0.4107   0.1335   0.1314     0.5872
LightGBM                  0.4539    0.4445   0.1826   0.1792     0.6354
Gradient Boosting         0.4474    0.4398   0.1727   0.1703     0.6276

=== PER-CLASS AUC (OvR) ===
Model                      AwayWin        Draw     HomeWin
----------------------------------------------------------
Random Forest               0.6965      0.5201      0.6955
Neural Network              0.7087      0.5481      0.7063
Extra Trees                 0.6919      0.5436      0.6972
SVM                         0.6942      0.5517      0.6984
CatBoost                    0.7164      0.5589      0.7129
Logistic Regression         0.7135      0.5551      0.7102
AdaBoost                    0.7062      0.5504      0.7074
XGBoost                     0.6898      0.5328      0.6814
KNN                         0.6227      0.5158      0.6228
LightGBM                    0.6897      0.5281      0.6880
Gradient Boosting           0.6801      0.5241      0.6782

=== CALIBRATED vs UNCALIBRATED MACRO AUC ===
Model                     Raw AUC    Cal AUC    Delta
------------------------------------------------------
Random Forest              0.6374     0.6405  +0.0031
Neural Network             0.6545     0.6579  +0.0034
Extra Trees                0.6442     0.6471  +0.0028
SVM                        0.6483     0.6429  -0.0054
CatBoost                   0.6629     0.6645  +0.0016
Logistic Regression        0.6598     0.6594  -0.0003
AdaBoost                   0.6547     0.6580  +0.0033
XGBoost                    0.6348     0.6386  +0.0038
KNN                        0.5872     0.5923  +0.0051
LightGBM                   0.6354     0.6397  +0.0043
Gradient Boosting          0.6276     0.6295  +0.0019

=== OPTIMISED THRESHOLD METRICS ===
Model                   Acc(def)  Acc(opt)  BalAcc(def)  BalAcc(opt)
----------------------------------------------------------------------
Random Forest             0.5197    0.4910       0.4432       0.4487
Neural Network            0.5183    0.5081       0.4528       0.4623
Extra Trees               0.5134    0.4672       0.4416       0.4535
SVM                       0.4839    0.5178       0.4609       0.4558
CatBoost                  0.4733    0.5010       0.4630       0.4764
Logistic Regression       0.4678    0.4851       0.4684       0.4630
AdaBoost                  0.4640    0.4455       0.4656       0.4526
XGBoost                   0.4554    0.4588       0.4487       0.4496
KNN                       0.4541    0.4045       0.4107       0.3995
LightGBM                  0.4539    0.4501       0.4445       0.4466
Gradient Boosting         0.4474    0.4626       0.4398       0.4381

=== OPTIMAL THRESHOLDS (OvR, on calibration set) ===
Model                            AwayWin              Draw           HomeWin
----------------------------------------------------------------------------
Random Forest            0.281 (f1=0.55)   0.223 (f1=0.43)   0.321 (f1=0.64)
Neural Network           0.240 (f1=0.55)   0.241 (f1=0.44)   0.322 (f1=0.63)
Extra Trees              0.319 (f1=0.55)   0.238 (f1=0.44)   0.382 (f1=0.63)
SVM                      0.265 (f1=0.55)   0.232 (f1=0.43)   0.288 (f1=0.63)
CatBoost                 0.283 (f1=0.56)   0.226 (f1=0.45)   0.325 (f1=0.65)
Logistic Regression      0.282 (f1=0.56)   0.220 (f1=0.44)   0.345 (f1=0.65)
AdaBoost                 0.306 (f1=0.56)   0.216 (f1=0.44)   0.376 (f1=0.64)
XGBoost                  0.307 (f1=0.55)   0.231 (f1=0.44)   0.340 (f1=0.63)
KNN                      0.283 (f1=0.51)   0.217 (f1=0.42)   0.349 (f1=0.61)
LightGBM                 0.262 (f1=0.55)   0.213 (f1=0.44)   0.351 (f1=0.64)
Gradient Boosting        0.310 (f1=0.56)   0.246 (f1=0.44)   0.381 (f1=0.64)

=== DETAILED RESULTS ===

Model: Random Forest
------------------------------
Accuracy:          0.5197
Balanced Accuracy: 0.4432
MCC:               0.2257
Cohen's Kappa:     0.1988
Macro ROC-AUC:     0.6374
Calibrated AUC:    0.6405
Accuracy (opt thr): 0.4910
Bal.Acc (opt thr):  0.4487

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.53      0.44      0.48      1593
        Draw       0.27      0.04      0.07      1338
     HomeWin       0.53      0.85      0.65      2330

    accuracy                           0.52      5261
   macro avg       0.44      0.44      0.40      5261
weighted avg       0.46      0.52      0.45      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.52      0.38      0.44      1593
        Draw       0.30      0.27      0.28      1338
     HomeWin       0.56      0.69      0.62      2330

    accuracy                           0.49      5261
   macro avg       0.46      0.45      0.45      5261
weighted avg       0.48      0.49      0.48      5261

Confusion Matrix:
[[ 698   78  817]
 [ 339   55  944]
 [ 275   74 1981]]
======================================================================
Model: Neural Network
------------------------------
Accuracy:          0.5183
Balanced Accuracy: 0.4528
MCC:               0.2286
Cohen's Kappa:     0.2123
Macro ROC-AUC:     0.6545
Calibrated AUC:    0.6579
Accuracy (opt thr): 0.5081
Bal.Acc (opt thr):  0.4623

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.50      0.53      0.51      1593
        Draw       0.26      0.05      0.08      1338
     HomeWin       0.55      0.78      0.65      2330

    accuracy                           0.52      5261
   macro avg       0.43      0.45      0.41      5261
weighted avg       0.46      0.52      0.46      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.45      0.65      0.53      1593
        Draw       0.29      0.08      0.13      1338
     HomeWin       0.59      0.66      0.62      2330

    accuracy                           0.51      5261
   macro avg       0.44      0.46      0.43      5261
weighted avg       0.47      0.51      0.47      5261

Confusion Matrix:
[[ 843   90  660]
 [ 446   65  827]
 [ 413   98 1819]]
======================================================================
Model: Extra Trees
------------------------------
Accuracy:          0.5134
Balanced Accuracy: 0.4416
MCC:               0.2159
Cohen's Kappa:     0.1948
Macro ROC-AUC:     0.6442
Calibrated AUC:    0.6471
Accuracy (opt thr): 0.4672
Bal.Acc (opt thr):  0.4535

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.50      0.47      0.48      1593
        Draw       0.27      0.04      0.07      1338
     HomeWin       0.53      0.81      0.64      2330

    accuracy                           0.51      5261
   macro avg       0.43      0.44      0.40      5261
weighted avg       0.45      0.51      0.45      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.49      0.46      0.48      1593
        Draw       0.28      0.37      0.32      1338
     HomeWin       0.62      0.52      0.57      2330

    accuracy                           0.47      5261
   macro avg       0.46      0.45      0.45      5261
weighted avg       0.49      0.47      0.48      5261

Confusion Matrix:
[[ 754   79  760]
 [ 391   50  897]
 [ 375   58 1897]]
======================================================================
Model: SVM
------------------------------
Accuracy:          0.4839
Balanced Accuracy: 0.4609
MCC:               0.2102
Cohen's Kappa:     0.2092
Macro ROC-AUC:     0.6483
Calibrated AUC:    0.6429
Accuracy (opt thr): 0.5178
Bal.Acc (opt thr):  0.4558

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.46      0.56      0.51      1593
        Draw       0.29      0.26      0.28      1338
     HomeWin       0.62      0.56      0.59      2330

    accuracy                           0.48      5261
   macro avg       0.46      0.46      0.46      5261
weighted avg       0.49      0.48      0.48      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.48      0.57      0.52      1593
        Draw       0.28      0.04      0.07      1338
     HomeWin       0.56      0.75      0.64      2330

    accuracy                           0.52      5261
   macro avg       0.44      0.46      0.41      5261
weighted avg       0.46      0.52      0.46      5261

Confusion Matrix:
[[ 893  357  343]
 [ 524  354  460]
 [ 507  524 1299]]
======================================================================
Model: CatBoost
------------------------------
Accuracy:          0.4733
Balanced Accuracy: 0.4630
MCC:               0.2138
Cohen's Kappa:     0.2071
Macro ROC-AUC:     0.6629
Calibrated AUC:    0.6645
Accuracy (opt thr): 0.5010
Bal.Acc (opt thr):  0.4764

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.56      0.37      0.44      1593
        Draw       0.29      0.48      0.36      1338
     HomeWin       0.63      0.54      0.58      2330

    accuracy                           0.47      5261
   macro avg       0.49      0.46      0.46      5261
weighted avg       0.52      0.47      0.48      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.50      0.56      0.53      1593
        Draw       0.30      0.28      0.29      1338
     HomeWin       0.62      0.59      0.60      2330

    accuracy                           0.50      5261
   macro avg       0.47      0.48      0.47      5261
weighted avg       0.50      0.50      0.50      5261

Confusion Matrix:
[[ 585  711  297]
 [ 253  642  443]
 [ 209  858 1263]]
Training curve: metric=MultiClass, best_iter=40, final_train=0.9404, final_val=1.0107

======================================================================
Model: Logistic Regression
------------------------------
Accuracy:          0.4678
Balanced Accuracy: 0.4684
MCC:               0.2143
Cohen's Kappa:     0.2090
Macro ROC-AUC:     0.6598
Calibrated AUC:    0.6594
Accuracy (opt thr): 0.4851
Bal.Acc (opt thr):  0.4630

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.48      0.53      0.51      1593
        Draw       0.29      0.42      0.35      1338
     HomeWin       0.66      0.45      0.53      2330

    accuracy                           0.47      5261
   macro avg       0.48      0.47      0.46      5261
weighted avg       0.51      0.47      0.48      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.52      0.46      0.49      1593
        Draw       0.29      0.35      0.32      1338
     HomeWin       0.61      0.58      0.59      2330

    accuracy                           0.49      5261
   macro avg       0.47      0.46      0.47      5261
weighted avg       0.50      0.49      0.49      5261

Confusion Matrix:
[[ 852  526  215]
 [ 452  565  321]
 [ 457  829 1044]]
======================================================================
Model: AdaBoost
------------------------------
Accuracy:          0.4640
Balanced Accuracy: 0.4656
MCC:               0.2129
Cohen's Kappa:     0.2053
Macro ROC-AUC:     0.6547
Calibrated AUC:    0.6580
Accuracy (opt thr): 0.4455
Bal.Acc (opt thr):  0.4526

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.53      0.47      0.50      1593
        Draw       0.28      0.47      0.35      1338
     HomeWin       0.65      0.46      0.54      2330

    accuracy                           0.46      5261
   macro avg       0.49      0.47      0.46      5261
weighted avg       0.52      0.46      0.48      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.60      0.29      0.39      1593
        Draw       0.29      0.61      0.39      1338
     HomeWin       0.65      0.46      0.54      2330

    accuracy                           0.45      5261
   macro avg       0.51      0.45      0.44      5261
weighted avg       0.54      0.45      0.46      5261

Confusion Matrix:
[[ 743  629  221]
 [ 362  634  342]
 [ 295  971 1064]]
======================================================================
Model: XGBoost
------------------------------
Accuracy:          0.4554
Balanced Accuracy: 0.4487
MCC:               0.1881
Cohen's Kappa:     0.1837
Macro ROC-AUC:     0.6348
Calibrated AUC:    0.6386
Accuracy (opt thr): 0.4588
Bal.Acc (opt thr):  0.4496

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.44      0.60      0.51      1593
        Draw       0.28      0.30      0.29      1338
     HomeWin       0.64      0.45      0.52      2330

    accuracy                           0.46      5261
   macro avg       0.45      0.45      0.44      5261
weighted avg       0.49      0.46      0.46      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.47      0.52      0.49      1593
        Draw       0.27      0.35      0.31      1338
     HomeWin       0.63      0.48      0.54      2330

    accuracy                           0.46      5261
   macro avg       0.46      0.45      0.45      5261
weighted avg       0.49      0.46      0.47      5261

Confusion Matrix:
[[ 956  400  237]
 [ 582  402  354]
 [ 653  639 1038]]
Training curve: metric=mlogloss, best_iter=39, final_train=0.7238, final_val=1.0688

======================================================================
Model: KNN
------------------------------
Accuracy:          0.4541
Balanced Accuracy: 0.4107
MCC:               0.1335
Cohen's Kappa:     0.1314
Macro ROC-AUC:     0.5872
Calibrated AUC:    0.5923
Accuracy (opt thr): 0.4045
Bal.Acc (opt thr):  0.3995

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.43      0.39      0.41      1593
        Draw       0.29      0.20      0.23      1338
     HomeWin       0.52      0.65      0.58      2330

    accuracy                           0.45      5261
   macro avg       0.41      0.41      0.41      5261
weighted avg       0.43      0.45      0.44      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.42      0.37      0.40      1593
        Draw       0.26      0.39      0.32      1338
     HomeWin       0.54      0.43      0.48      2330

    accuracy                           0.40      5261
   macro avg       0.41      0.40      0.40      5261
weighted avg       0.44      0.40      0.41      5261

Confusion Matrix:
[[ 620  286  687]
 [ 372  263  703]
 [ 464  360 1506]]
======================================================================
Model: LightGBM
------------------------------
Accuracy:          0.4539
Balanced Accuracy: 0.4445
MCC:               0.1826
Cohen's Kappa:     0.1792
Macro ROC-AUC:     0.6354
Calibrated AUC:    0.6397
Accuracy (opt thr): 0.4501
Bal.Acc (opt thr):  0.4466

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.44      0.59      0.50      1593
        Draw       0.27      0.29      0.28      1338
     HomeWin       0.63      0.46      0.53      2330

    accuracy                           0.45      5261
   macro avg       0.45      0.44      0.44      5261
weighted avg       0.48      0.45      0.46      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.47      0.46      0.47      1593
        Draw       0.28      0.42      0.33      1338
     HomeWin       0.63      0.46      0.53      2330

    accuracy                           0.45      5261
   macro avg       0.46      0.45      0.44      5261
weighted avg       0.50      0.45      0.46      5261

Confusion Matrix:
[[ 936  404  253]
 [ 575  386  377]
 [ 616  648 1066]]
Training curve: metric=multi_logloss, best_iter=17, final_train=0.6836, final_val=1.0574

======================================================================
Model: Gradient Boosting
------------------------------
Accuracy:          0.4474
Balanced Accuracy: 0.4398
MCC:               0.1727
Cohen's Kappa:     0.1703
Macro ROC-AUC:     0.6276
Calibrated AUC:    0.6295
Accuracy (opt thr): 0.4626
Bal.Acc (opt thr):  0.4381

Classification Report (default threshold):
              precision    recall  f1-score   support

     AwayWin       0.45      0.49      0.47      1593
        Draw       0.28      0.36      0.31      1338
     HomeWin       0.61      0.47      0.53      2330

    accuracy                           0.45      5261
   macro avg       0.45      0.44      0.44      5261
weighted avg       0.48      0.45      0.46      5261

Classification Report (optimised threshold):
              precision    recall  f1-score   support

     AwayWin       0.46      0.46      0.46      1593
        Draw       0.28      0.29      0.29      1338
     HomeWin       0.58      0.56      0.57      2330

    accuracy                           0.46      5261
   macro avg       0.44      0.44      0.44      5261
weighted avg       0.47      0.46      0.46      5261

Confusion Matrix:
[[ 786  511  296]
 [ 467  481  390]
 [ 497  746 1087]]
Training curve: metric=accuracy, best_iter=18, final_train=0.5665, final_val=0.4474

======================================================================
