Results for Full Dataset - Away_Win
======================================================================

=== RANKING TABLE ===
Model                   Accuracy   Bal.Acc      MCC    Kappa   ROC-AUC
----------------------------------------------------------------------
Extra Trees               0.7151    0.5510   0.1916   0.1313    0.6868
AdaBoost                  0.7134    0.6433   0.2981   0.2969    0.7059
Random Forest             0.7027    0.5157   0.1039   0.0426    0.6800
KNN                       0.6847    0.5748   0.1745   0.1669    0.6227
LightGBM                  0.6664    0.6441   0.2719   0.2673    0.6947
CatBoost                  0.6632    0.6564   0.2910   0.2816    0.7187
SVM                       0.6560    0.6451   0.2707   0.2627    0.6854
Logistic Regression       0.6379    0.6544   0.2839   0.2647    0.7144
Gradient Boosting         0.6200    0.6306   0.2402   0.2249    0.6836

=== CALIBRATED vs UNCALIBRATED ROC-AUC ===
Model                    Uncalibrated   Calibrated    Delta
------------------------------------------------------------
Extra Trees                    0.6868          N/A      N/A
AdaBoost                       0.7059          N/A      N/A
Random Forest                  0.6800          N/A      N/A
KNN                            0.6227          N/A      N/A
LightGBM                       0.6947          N/A      N/A
CatBoost                       0.7187          N/A      N/A
SVM                            0.6854          N/A      N/A
Logistic Regression            0.7144          N/A      N/A
Gradient Boosting              0.6836          N/A      N/A

=== OPTIMISED THRESHOLD METRICS ===
Model                   Acc(default)   Acc(opt)  BalAcc(default)  BalAcc(opt)
-----------------------------------------------------------------------------
Extra Trees                   0.7151        N/A           0.5510          N/A
AdaBoost                      0.7134        N/A           0.6433          N/A
Random Forest                 0.7027        N/A           0.5157          N/A
KNN                           0.6847        N/A           0.5748          N/A
LightGBM                      0.6664        N/A           0.6441          N/A
CatBoost                      0.6632        N/A           0.6564          N/A
SVM                           0.6560        N/A           0.6451          N/A
Logistic Regression           0.6379        N/A           0.6544          N/A
Gradient Boosting             0.6200        N/A           0.6306          N/A

=== DETAILED RESULTS ===

Model: Extra Trees
------------------------------
Accuracy:          0.7151
Balanced Accuracy: 0.5510
MCC:               0.1916
Cohen's Kappa:     0.1313
ROC-AUC:           0.6868

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.72      0.97      0.83      3668
    Away Win       0.64      0.13      0.22      1593

    accuracy                           0.72      5261
   macro avg       0.68      0.55      0.52      5261
weighted avg       0.70      0.72      0.64      5261

Confusion Matrix:
[[3547  121]
 [1378  215]]
======================================================================
Model: AdaBoost
------------------------------
Accuracy:          0.7134
Balanced Accuracy: 0.6433
MCC:               0.2981
Cohen's Kappa:     0.2969
ROC-AUC:           0.7059

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.78      0.82      0.80      3668
    Away Win       0.53      0.47      0.50      1593

    accuracy                           0.71      5261
   macro avg       0.66      0.64      0.65      5261
weighted avg       0.70      0.71      0.71      5261

Confusion Matrix:
[[3011  657]
 [ 851  742]]
======================================================================
Model: Random Forest
------------------------------
Accuracy:          0.7027
Balanced Accuracy: 0.5157
MCC:               0.1039
Cohen's Kappa:     0.0426
ROC-AUC:           0.6800

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.70      0.99      0.82      3668
    Away Win       0.64      0.04      0.08      1593

    accuracy                           0.70      5261
   macro avg       0.67      0.52      0.45      5261
weighted avg       0.68      0.70      0.60      5261

Confusion Matrix:
[[3631   37]
 [1527   66]]
======================================================================
Model: KNN
------------------------------
Accuracy:          0.6847
Balanced Accuracy: 0.5748
MCC:               0.1745
Cohen's Kappa:     0.1669
ROC-AUC:           0.6227

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.74      0.85      0.79      3668
    Away Win       0.47      0.30      0.36      1593

    accuracy                           0.68      5261
   macro avg       0.60      0.57      0.58      5261
weighted avg       0.65      0.68      0.66      5261

Confusion Matrix:
[[3130  538]
 [1121  472]]
======================================================================
Model: LightGBM
------------------------------
Accuracy:          0.6664
Balanced Accuracy: 0.6441
MCC:               0.2719
Cohen's Kappa:     0.2673
ROC-AUC:           0.6947

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.80      0.70      0.75      3668
    Away Win       0.46      0.59      0.52      1593

    accuracy                           0.67      5261
   macro avg       0.63      0.64      0.63      5261
weighted avg       0.69      0.67      0.68      5261

Confusion Matrix:
[[2570 1098]
 [ 657  936]]
Training curve: metric=binary_logloss, best_iter=44, final_train=0.4327, final_val=0.6167

======================================================================
Model: CatBoost
------------------------------
Accuracy:          0.6632
Balanced Accuracy: 0.6564
MCC:               0.2910
Cohen's Kappa:     0.2816
ROC-AUC:           0.7187

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.81      0.67      0.74      3668
    Away Win       0.46      0.64      0.53      1593

    accuracy                           0.66      5261
   macro avg       0.64      0.66      0.64      5261
weighted avg       0.70      0.66      0.68      5261

Confusion Matrix:
[[2471 1197]
 [ 575 1018]]
Training curve: metric=Logloss, best_iter=24, final_train=0.5532, final_val=0.6209

======================================================================
Model: SVM
------------------------------
Accuracy:          0.6560
Balanced Accuracy: 0.6451
MCC:               0.2707
Cohen's Kappa:     0.2627
ROC-AUC:           0.6854

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.80      0.67      0.73      3668
    Away Win       0.45      0.62      0.52      1593

    accuracy                           0.66      5261
   macro avg       0.63      0.65      0.63      5261
weighted avg       0.70      0.66      0.67      5261

Confusion Matrix:
[[2467 1201]
 [ 609  984]]
======================================================================
Model: Logistic Regression
------------------------------
Accuracy:          0.6379
Balanced Accuracy: 0.6544
MCC:               0.2839
Cohen's Kappa:     0.2647
ROC-AUC:           0.7144

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.82      0.61      0.70      3668
    Away Win       0.44      0.70      0.54      1593

    accuracy                           0.64      5261
   macro avg       0.63      0.65      0.62      5261
weighted avg       0.71      0.64      0.65      5261

Confusion Matrix:
[[2247 1421]
 [ 484 1109]]
======================================================================
Model: Gradient Boosting
------------------------------
Accuracy:          0.6200
Balanced Accuracy: 0.6306
MCC:               0.2402
Cohen's Kappa:     0.2249
ROC-AUC:           0.6836

Classification Report:
              precision    recall  f1-score   support

Not Away Win       0.80      0.60      0.69      3668
    Away Win       0.42      0.66      0.51      1593

    accuracy                           0.62      5261
   macro avg       0.61      0.63      0.60      5261
weighted avg       0.69      0.62      0.64      5261

Confusion Matrix:
[[2215 1453]
 [ 546 1047]]
Training curve: metric=accuracy, best_iter=2, final_train=0.7115, final_val=0.6200

======================================================================
