Results for Full Dataset - Home_Win
======================================================================

=== RANKING TABLE ===
Model                   Accuracy   Bal.Acc      MCC    Kappa   ROC-AUC
----------------------------------------------------------------------
CatBoost                  0.6600    0.6534   0.3083   0.3081    0.7119
AdaBoost                  0.6592    0.6522   0.3063   0.3060    0.7055
Logistic Regression       0.6580    0.6454   0.2988   0.2956    0.7106
SVM                       0.6535    0.6477   0.2962   0.2962    0.6930
Extra Trees               0.6421    0.6234   0.2623   0.2539    0.6971
LightGBM                  0.6331    0.6130   0.2426   0.2332    0.6724
Random Forest             0.6316    0.6112   0.2392   0.2296    0.6803
Gradient Boosting         0.6309    0.6170   0.2414   0.2382    0.6737
KNN                       0.5961    0.5909   0.1818   0.1818    0.6228

=== CALIBRATED vs UNCALIBRATED ROC-AUC ===
Model                    Uncalibrated   Calibrated    Delta
------------------------------------------------------------
CatBoost                       0.7119          N/A      N/A
AdaBoost                       0.7055          N/A      N/A
Logistic Regression            0.7106          N/A      N/A
SVM                            0.6930          N/A      N/A
Extra Trees                    0.6971          N/A      N/A
LightGBM                       0.6724          N/A      N/A
Random Forest                  0.6803          N/A      N/A
Gradient Boosting              0.6737          N/A      N/A
KNN                            0.6228          N/A      N/A

=== OPTIMISED THRESHOLD METRICS ===
Model                   Acc(default)   Acc(opt)  BalAcc(default)  BalAcc(opt)
-----------------------------------------------------------------------------
CatBoost                      0.6600        N/A           0.6534          N/A
AdaBoost                      0.6592        N/A           0.6522          N/A
Logistic Regression           0.6580        N/A           0.6454          N/A
SVM                           0.6535        N/A           0.6477          N/A
Extra Trees                   0.6421        N/A           0.6234          N/A
LightGBM                      0.6331        N/A           0.6130          N/A
Random Forest                 0.6316        N/A           0.6112          N/A
Gradient Boosting             0.6309        N/A           0.6170          N/A
KNN                           0.5961        N/A           0.5909          N/A

=== DETAILED RESULTS ===

Model: CatBoost
------------------------------
Accuracy:          0.6600
Balanced Accuracy: 0.6534
MCC:               0.3083
Cohen's Kappa:     0.3081
ROC-AUC:           0.7119

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.69      0.71      0.70      2931
    Home Win       0.62      0.60      0.61      2330

    accuracy                           0.66      5261
   macro avg       0.65      0.65      0.65      5261
weighted avg       0.66      0.66      0.66      5261

Confusion Matrix:
[[2083  848]
 [ 941 1389]]
Training curve: metric=Logloss, best_iter=36, final_train=0.5693, final_val=0.6341

======================================================================
Model: AdaBoost
------------------------------
Accuracy:          0.6592
Balanced Accuracy: 0.6522
MCC:               0.3063
Cohen's Kappa:     0.3060
ROC-AUC:           0.7055

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.69      0.71      0.70      2931
    Home Win       0.62      0.59      0.61      2330

    accuracy                           0.66      5261
   macro avg       0.65      0.65      0.65      5261
weighted avg       0.66      0.66      0.66      5261

Confusion Matrix:
[[2090  841]
 [ 952 1378]]
======================================================================
Model: Logistic Regression
------------------------------
Accuracy:          0.6580
Balanced Accuracy: 0.6454
MCC:               0.2988
Cohen's Kappa:     0.2956
ROC-AUC:           0.7106

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.67      0.76      0.71      2931
    Home Win       0.64      0.53      0.58      2330

    accuracy                           0.66      5261
   macro avg       0.65      0.65      0.65      5261
weighted avg       0.66      0.66      0.65      5261

Confusion Matrix:
[[2216  715]
 [1084 1246]]
======================================================================
Model: SVM
------------------------------
Accuracy:          0.6535
Balanced Accuracy: 0.6477
MCC:               0.2962
Cohen's Kappa:     0.2962
ROC-AUC:           0.6930

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.69      0.70      0.69      2931
    Home Win       0.61      0.60      0.60      2330

    accuracy                           0.65      5261
   macro avg       0.65      0.65      0.65      5261
weighted avg       0.65      0.65      0.65      5261

Confusion Matrix:
[[2046  885]
 [ 938 1392]]
======================================================================
Model: Extra Trees
------------------------------
Accuracy:          0.6421
Balanced Accuracy: 0.6234
MCC:               0.2623
Cohen's Kappa:     0.2539
ROC-AUC:           0.6971

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.65      0.79      0.71      2931
    Home Win       0.63      0.46      0.53      2330

    accuracy                           0.64      5261
   macro avg       0.64      0.62      0.62      5261
weighted avg       0.64      0.64      0.63      5261

Confusion Matrix:
[[2306  625]
 [1258 1072]]
======================================================================
Model: LightGBM
------------------------------
Accuracy:          0.6331
Balanced Accuracy: 0.6130
MCC:               0.2426
Cohen's Kappa:     0.2332
ROC-AUC:           0.6724

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.64      0.79      0.71      2931
    Home Win       0.62      0.44      0.51      2330

    accuracy                           0.63      5261
   macro avg       0.63      0.61      0.61      5261
weighted avg       0.63      0.63      0.62      5261

Confusion Matrix:
[[2313  618]
 [1312 1018]]
Training curve: metric=binary_logloss, best_iter=29, final_train=0.4637, final_val=0.6434

======================================================================
Model: Random Forest
------------------------------
Accuracy:          0.6316
Balanced Accuracy: 0.6112
MCC:               0.2392
Cohen's Kappa:     0.2296
ROC-AUC:           0.6803

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.64      0.79      0.70      2931
    Home Win       0.62      0.43      0.51      2330

    accuracy                           0.63      5261
   macro avg       0.63      0.61      0.61      5261
weighted avg       0.63      0.63      0.62      5261

Confusion Matrix:
[[2315  616]
 [1322 1008]]
======================================================================
Model: Gradient Boosting
------------------------------
Accuracy:          0.6309
Balanced Accuracy: 0.6170
MCC:               0.2414
Cohen's Kappa:     0.2382
ROC-AUC:           0.6737

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.65      0.74      0.69      2931
    Home Win       0.60      0.50      0.54      2330

    accuracy                           0.63      5261
   macro avg       0.62      0.62      0.62      5261
weighted avg       0.63      0.63      0.63      5261

Confusion Matrix:
[[2165  766]
 [1176 1154]]
Training curve: metric=accuracy, best_iter=31, final_train=0.6826, final_val=0.6309

======================================================================
Model: KNN
------------------------------
Accuracy:          0.5961
Balanced Accuracy: 0.5909
MCC:               0.1818
Cohen's Kappa:     0.1818
ROC-AUC:           0.6228

Classification Report:
              precision    recall  f1-score   support

Not Home Win       0.64      0.64      0.64      2931
    Home Win       0.54      0.55      0.54      2330

    accuracy                           0.60      5261
   macro avg       0.59      0.59      0.59      5261
weighted avg       0.60      0.60      0.60      5261

Confusion Matrix:
[[1864 1067]
 [1058 1272]]
======================================================================
